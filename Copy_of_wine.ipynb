{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of wine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvh4Y1A2znfbuXfsnhYy+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murraycoding/Artificial-Intelligence/blob/main/Copy_of_wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2JTtSI7cGJF"
      },
      "source": [
        "# Machine Learning Wine Classification Project\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlhjUFcASpZ7"
      },
      "source": [
        "# tensorflow version to use\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "# imports\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMwOwJ9ecufU"
      },
      "source": [
        "## Data Prep\n",
        "\n",
        "### Loading the data\n",
        "In this section, we will take the csv files from my GitHub account and read them in as csv files with pandas. From there, we can convert the csv files into traditional Panads dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPk_3ObBcyin"
      },
      "source": [
        "# urls of the data\n",
        "red_url = 'https://raw.githubusercontent.com/murraycoding/Artificial-Intelligence/main/winequality-red.csv'\n",
        "white_url = 'https://raw.githubusercontent.com/murraycoding/Artificial-Intelligence/main/winequality-white.csv'\n",
        "# open the urls with pandas\n",
        "red_csv = pd.read_csv(red_url, sep=';')\n",
        "white_csv = pd.read_csv(white_url, sep=';')\n",
        "# change to dataframes\n",
        "red_df = pd.DataFrame(red_csv, dtype='float64')\n",
        "white_df = pd.DataFrame(white_csv, dtype='float64')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRSFQWBdcFCg"
      },
      "source": [
        "### Preparing the data\n",
        "In the code below, the quality column from the original CSV will be removed and replaced by the color of the wine. In this example, we will attempt to use machine learning to predict the color of the wine based on a number of factors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k2k-FxYchFX",
        "outputId": "9076833f-0860-4b79-fe01-14efdb2056a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# replacing the last column with the color of the wine\n",
        "red_df = red_df.assign(color=0)\n",
        "white_df = white_df.assign(color=1)\n",
        "\n",
        "# determines the number of training data points from the dataset to take\n",
        "num_eval = 300\n",
        "\n",
        "# gets the evaluation data out of the original wine data\n",
        "red_df_eval = red_df[:num_eval]\n",
        "red_df_train = red_df[num_eval:]\n",
        "white_df_eval = white_df[:num_eval]\n",
        "white_df_train = white_df[num_eval:]\n",
        "\n",
        "# one new combined dataframe with both the red and the white wine data (both training and evaluation data)\n",
        "wine_df_train = pd.concat([red_df_train,white_df_train], ignore_index=True)\n",
        "wine_df_eval = pd.concat([red_df_eval,white_df_eval], ignore_index=True)\n",
        "wine_df_train.reset_index()\n",
        "wine_df_eval.reset_index()\n",
        "\n",
        "# separates the data into data and results\n",
        "wine_df_train_result = wine_df_train['color']\n",
        "wine_df_train_data = wine_df_train.drop(columns=['color','quality'], axis=1)\n",
        "wine_df_eval_result = wine_df_eval['color']\n",
        "wine_df_eval_data = wine_df_eval.drop(columns=['color','quality'], axis=1)\n",
        "\n",
        "print(wine_df_eval_data)\n",
        "# print(wine_df_eval_data)\n",
        "print(red_df_train)\n",
        "# print(red_df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     fixedacidity  volatileacidity  citricacid  ...    pH  sulphates  alcohol\n",
            "0             7.4             0.70        0.00  ...  3.51       0.56      9.4\n",
            "1             7.8             0.88        0.00  ...  3.20       0.68      9.8\n",
            "2             7.8             0.76        0.04  ...  3.26       0.65      9.8\n",
            "3            11.2             0.28        0.56  ...  3.16       0.58      9.8\n",
            "4             7.4             0.70        0.00  ...  3.51       0.56      9.4\n",
            "..            ...              ...         ...  ...   ...        ...      ...\n",
            "595           6.3             0.33        0.27  ...  3.37       0.54      9.4\n",
            "596           8.3             0.39        0.70  ...  3.09       0.57      9.4\n",
            "597           7.2             0.19        0.46  ...  3.19       0.60     11.2\n",
            "598           7.5             0.17        0.44  ...  3.17       0.45     10.0\n",
            "599           6.7             0.17        0.50  ...  3.15       0.45     10.3\n",
            "\n",
            "[600 rows x 11 columns]\n",
            "      fixedacidity  volatileacidity  citricacid  ...  alcohol  quality  color\n",
            "300            7.5            0.530        0.06  ...     10.7      6.0      0\n",
            "301           11.1            0.180        0.48  ...     10.1      6.0      0\n",
            "302            8.3            0.705        0.12  ...     10.0      5.0      0\n",
            "303            7.4            0.670        0.12  ...      9.5      5.0      0\n",
            "304            8.4            0.650        0.60  ...      9.2      5.0      0\n",
            "...            ...              ...         ...  ...      ...      ...    ...\n",
            "1594           6.2            0.600        0.08  ...     10.5      5.0      0\n",
            "1595           5.9            0.550        0.10  ...     11.2      6.0      0\n",
            "1596           6.3            0.510        0.13  ...     11.0      6.0      0\n",
            "1597           5.9            0.645        0.12  ...     10.2      5.0      0\n",
            "1598           6.0            0.310        0.47  ...     11.0      6.0      0\n",
            "\n",
            "[1299 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkz_zTpAdLd0"
      },
      "source": [
        "## Training the model\n",
        "In this section, we will train the model we will use to make predictions on the evaluation data selected from the csv data set at the start of the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SfTe1BZRnXX"
      },
      "source": [
        "### Input Function\n",
        "This is a pretty general input function from tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wu8QQVqRqfU"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjW0NozAT0FM"
      },
      "source": [
        "### Feature Columns\n",
        "In this section of code the feature columns are determined in to pass along to the input function and the estimator model from TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKKkZIyuTqp0",
        "outputId": "2974d582-5c73-43c4-956d-463b031954f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Feature columns describe how to use the input.\n",
        "my_feature_columns = []\n",
        "for key in wine_df_train_data.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(my_feature_columns)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='fixedacidity', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='volatileacidity', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='citricacid', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='residualsugar', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='chlorides', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='freesulfurdioxide', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='totalsulfurdioxide', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='density', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='pH', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='sulphates', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='alcohol', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTdUH7dqUr4k"
      },
      "source": [
        "### Building the model\n",
        "We are now ready to choose a model. For classification, there are a variety of different models that we can pick from. In this case, we will be using the DNNClassifier (Deep Neural Network). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwm7P3d5VBTn",
        "outputId": "1c0ea6b7-e87b-4549-b54b-5edc22d3389b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "my_head = tf.estimator.LogisticRegressionHead()\n",
        "# Build a DNN with 2 hidden layers with 25 and 15 hidden nodes each.\n",
        "classifier = tf.estimator.DNNEstimator(\n",
        "    head = my_head,\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    hidden_units=[25, 15])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpbzgtqlfs\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpbzgtqlfs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MZadqWTVIHb"
      },
      "source": [
        "### Training\n",
        "Now it's time to train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIKImtxFVMm7",
        "outputId": "f8ffc5a7-3c9d-4f08-dae8-07b9ddaf8f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(wine_df_train_data, wine_df_train_result, training=True),\n",
        "    steps=5000)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer hiddenlayer_0 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpbzgtqlfs/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.0033873103, step = 0\n",
            "INFO:tensorflow:global_step/sec: 328.194\n",
            "INFO:tensorflow:loss = 12.013993, step = 100 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.433\n",
            "INFO:tensorflow:loss = 3.474575, step = 200 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 426.156\n",
            "INFO:tensorflow:loss = 1.0785754, step = 300 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.209\n",
            "INFO:tensorflow:loss = 0.5152866, step = 400 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.111\n",
            "INFO:tensorflow:loss = 0.21009476, step = 500 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.547\n",
            "INFO:tensorflow:loss = 1.1334698, step = 600 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 447.808\n",
            "INFO:tensorflow:loss = 0.2837516, step = 700 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.092\n",
            "INFO:tensorflow:loss = 0.13007882, step = 800 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.888\n",
            "INFO:tensorflow:loss = 0.9453509, step = 900 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.244\n",
            "INFO:tensorflow:loss = 0.17957073, step = 1000 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.337\n",
            "INFO:tensorflow:loss = 0.13109761, step = 1100 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.22\n",
            "INFO:tensorflow:loss = 0.674463, step = 1200 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.23\n",
            "INFO:tensorflow:loss = 0.21402837, step = 1300 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 430.322\n",
            "INFO:tensorflow:loss = 0.11873865, step = 1400 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.501\n",
            "INFO:tensorflow:loss = 0.46842167, step = 1500 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.323\n",
            "INFO:tensorflow:loss = 0.14543346, step = 1600 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.297\n",
            "INFO:tensorflow:loss = 0.11625475, step = 1700 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.23\n",
            "INFO:tensorflow:loss = 0.44585788, step = 1800 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.666\n",
            "INFO:tensorflow:loss = 0.13079211, step = 1900 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.731\n",
            "INFO:tensorflow:loss = 0.12011963, step = 2000 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 408.675\n",
            "INFO:tensorflow:loss = 0.41846186, step = 2100 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.43\n",
            "INFO:tensorflow:loss = 0.15040928, step = 2200 (0.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.778\n",
            "INFO:tensorflow:loss = 0.113671824, step = 2300 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 423.322\n",
            "INFO:tensorflow:loss = 0.36121508, step = 2400 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.125\n",
            "INFO:tensorflow:loss = 0.13994566, step = 2500 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.15\n",
            "INFO:tensorflow:loss = 0.10736698, step = 2600 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.36\n",
            "INFO:tensorflow:loss = 0.31929243, step = 2700 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 435.075\n",
            "INFO:tensorflow:loss = 0.14375845, step = 2800 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.794\n",
            "INFO:tensorflow:loss = 0.105556205, step = 2900 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 417.094\n",
            "INFO:tensorflow:loss = 0.2251837, step = 3000 (0.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.486\n",
            "INFO:tensorflow:loss = 0.13298354, step = 3100 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.162\n",
            "INFO:tensorflow:loss = 0.11886715, step = 3200 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.113\n",
            "INFO:tensorflow:loss = 0.24833591, step = 3300 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 410.046\n",
            "INFO:tensorflow:loss = 0.13033572, step = 3400 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.88\n",
            "INFO:tensorflow:loss = 0.11417324, step = 3500 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 444.653\n",
            "INFO:tensorflow:loss = 0.23347518, step = 3600 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.096\n",
            "INFO:tensorflow:loss = 0.12436587, step = 3700 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 424.394\n",
            "INFO:tensorflow:loss = 0.17887256, step = 3800 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 424.762\n",
            "INFO:tensorflow:loss = 0.17059085, step = 3900 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 410.457\n",
            "INFO:tensorflow:loss = 0.13619205, step = 4000 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.93\n",
            "INFO:tensorflow:loss = 0.42538017, step = 4100 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 420.644\n",
            "INFO:tensorflow:loss = 0.20042393, step = 4200 (0.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.655\n",
            "INFO:tensorflow:loss = 0.11430917, step = 4300 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.42\n",
            "INFO:tensorflow:loss = 0.56005144, step = 4400 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.924\n",
            "INFO:tensorflow:loss = 0.10247417, step = 4500 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.056\n",
            "INFO:tensorflow:loss = 0.116496734, step = 4600 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.334\n",
            "INFO:tensorflow:loss = 0.529637, step = 4700 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.716\n",
            "INFO:tensorflow:loss = 0.13174151, step = 4800 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.358\n",
            "INFO:tensorflow:loss = 0.17719123, step = 4900 (0.230 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpbzgtqlfs/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.63550055.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNEstimatorV2 at 0x7ff6ca284630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VXQa4gKanDA",
        "outputId": "571b40b1-1c6e-4e94-baed-f58667f9d718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "eval_result = classifier.evaluate(input_fn=lambda: input_fn(wine_df_eval_data, wine_df_eval_result, training=False))\n",
        "print(eval_result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer hiddenlayer_0 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-11-05T18:53:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpbzgtqlfs/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.26767s\n",
            "INFO:tensorflow:Finished evaluation at 2020-11-05-18:53:29\n",
            "INFO:tensorflow:Saving dict for global step 5000: average_loss = 0.5623307212754722, global_step = 5000, label/mean = 0.5, loss = 0.4496868, prediction/mean = 0.6967617181936899\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpbzgtqlfs/model.ckpt-5000\n",
            "{'average_loss': 0.5623307212754722, 'label/mean': 0.5, 'loss': 0.4496868, 'prediction/mean': 0.6967617181936899, 'global_step': 5000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upP275q6lXqz"
      },
      "source": [
        "### Using the model\n",
        "We will now use the model by allowing the user to input a series of statistics about a new wine. The model will then give a prediction about if the wine being tested in red or white."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czJQZmfrlzXS",
        "outputId": "0898d9e7-ef41-4940-9fc7-2c2e444686a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creates a new input function just for predictions\n",
        "def predict_input_fn(features, batch_size=256):\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "# wine types\n",
        "wine_type = ('white','red')\n",
        "\n",
        "# wine dictionary to store user input\n",
        "user_wine = {}\n",
        "\n",
        "for feature in my_feature_columns:\n",
        "    # asks the user for input\n",
        "    value = input(f'{feature[0]} = ')\n",
        "    user_wine[feature] = [float(value)]\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: predict_input_fn(user_wine))\n",
        "for predict_dict in predictions:\n",
        "    # print(predict_dict)\n",
        "    print(f\"Chance of white wine: {round(predict_dict['probabilities'][0]*100,1)}%\")\n",
        "    print(f\"Chance of red wine: {round(predict_dict['probabilities'][1]*100,1)}%\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fixedacidity = 2\n",
            "volatileacidity = 2\n",
            "citricacid = 2\n",
            "residualsugar = 2\n",
            "chlorides = 2\n",
            "freesulfurdioxide = 2\n",
            "totalsulfurdioxide = 2\n",
            "density = 2\n",
            "pH = 2\n",
            "sulphates = 2\n",
            "alcohol = 2\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpnb7jweop/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Chance of white wine: 78.5%\n",
            "Chance of red wine: 21.5%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}